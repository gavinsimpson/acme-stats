<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Importing data</title>
    <meta charset="utf-8" />
    <meta name="author" content="Gavin Simpson" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../common/css/all.css" type="text/css" />
    <link rel="stylesheet" href="../common/css/slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: inverse, middle, left, my-title-slide, title-slide

.title[
# Importing data
]
.subtitle[
## ACME Workshop
]
.author[
### Gavin Simpson
]

---





---
class: inverse middle center subsection

# The Tidyverse

---

# The Tidyverse

.row[

.col-9[
&gt; The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. &amp;mdash; **www.tidyverse.org**

]

.col-3[
.center[
&lt;img src="./resources/tidyverse-logo.png" width="320" /&gt;
]

]

]

---

# The Tidyverse

A meta package that installs a core set of the tidyverse packages

* **ggplot2** &amp;mdash; graphics &amp; data viz following *The Grammar of Graphics*
* **dplyr** &amp;mdash; a grammar of data manipulation
* **tidyr** &amp;mdash; functions to achieve a zen-like tidy state in your data üßò
* **readr** &amp;mdash; fast, friendly ways to read rectangular data (`.csv`, `.tsv`, `.fwf`)
* **purrr** &amp;mdash; enhanced functional programming replacing explicit loops
* **tibble** &amp;mdash; a modern reimgaining of the data frame
* **stringr** &amp;mdash; for working with strings in an easy manner
* **forcats** &amp;mdash; for working with factors &amp; categorical variables

---

# The Tidyverse

Addresses stages in the data science workflow

&lt;img src="resources/r4ds-data-science.png" width="689" style="display: block; margin: auto;" /&gt;

.references[Wickham &amp; Grolemund (2017) [R for Data Science](https://r4ds.had.co.nz/)]

---

# The Tidyverse

To install the suite of *tidyverse* packages use


```r
install.packages('tidyverse')
```

To use the core *tidyverse* suite of packages in your code load the *tidyverse* package


```r
library('tidyverse')
```

I don't recommend loading all the *tidyverse* this way though &amp;mdash; you should get into the habit of loading only the packages you will use / need

---

# Tidy data

&gt; Tidy datasets provide a standardized way to link the structure of a dataset (its physical layout) with its semantics (its meaning). &amp;mdash; **Hadley Wickham**

A way to arrange data that facilitates subsequent exploration, transformation, visualization, &amp; modelling of the data where

* each column is a variable
* each row is observation

---

# Reading data into R

There are many ways to read data into and out of R &amp;mdash; you don't need the Tidyverse for this

* `read.csv()` for example in base R

But&amp;hellip;

* if we're following the Tidy principles, or
* we just want a cleaner, more intuitive interface

then two tidyverse packages can help **readr** and **readxl**

---

# Packages üì¶

Unless you work with huge data sets or files created by subject-specific software (e.g. GIS)

Data are mostly arranged in rectangular files

* Plain text files (CSV, TSV, FWF) &amp;mdash; **readr** üì¶ or **vroom** üì¶

* Excel sheets or workbooks (Binary) &amp;mdash; **readxl** üì¶

---

# Reading rectangular data &amp;mdash; *readr* üì¶

There are a few functions to remember for reading data

* reading comma delimited files &amp;mdash; `read_csv("file.csv")`

* reading semi-colon delimited files &amp;mdash; `read_csv2("file2.csv")`

* reading files with any delimiter &amp;mdash; `read_delim("file.txt", delim = "|")`

* reading tab delimited files &amp;mdash; `read_tsv("file.tsv")`

* reading fixed-width files &amp;mdash; `read_fwf("file.fwf", col_positions = c(1, 3, 5))`

* reading files white-space-separated files &amp;mdash; `read_table("file.txt")`

---

# Reading rectangular data

Several common, key arguments (plus some others for special cases, like *locales*)

`col_names = TRUE` &amp;mdash; `TRUE` is the default, does the first row contain the column labels

`col_names = c('a', 'b', 'c')` &amp;mdash; give the column names to use explicitly. If you do:

**Must `skip = 1L` to skip reading the first row of data**

You can specify a column name as missing using `NA` &amp;mdash; replaced with `"X1"`, `"X2"` etc

---

# Reading rectangular data

`col_types` is the way to tell **readr** what data to expect

If not supplied **readr** will guess by reading the first `guess_max` rows

Can take 1 of 3 inputs

1. `NULL` &amp;mdash; the default. Guess the data types by reading the first `guess_max = 1000` rows

2. A `cols()` column specification

3. A string of abbreviations indicating column types

---

# `cols()`

.row[

.col-6[
A list of column specifiers or *prototypes*


```r
cols(col_integer(), col_logical())
```

```
## cols(
##   col_integer(),
##   col_logical()
## )
```
]

.col-6[
Lots of prototypes

See `?cols` for the full list

* `col_logical()` &amp;mdash; `'l'`
* `col_integer()` &amp;mdash; `'i'`
* `col_double()` &amp;mdash; `'d'`
* `col_character()` &amp;mdash; `'c'`
* `col_skip()` &amp;mdash; `'_'` or `'-'`
* `col_guess()` &amp;mdash; `'?'`
]
]

---

# Abbreviations

For data sets with many columns it is quicker to use the abbreviated form

`col_types = "-iddc?"`

Means

* skip the first column
* second column is an integer
* third and fourth columns are double
* fifth column is text/character
* guess the sixth column

---

# `spec()` &amp; `problems()`

.smaller[

```r
dinocyst &lt;- read_csv(here("data", "dinocyst-spp.csv"), skip = 2)
```

```
## Rows: 1968 Columns: 72
## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## Delimiter: ","
## chr  (1): Site number
## dbl (71): Aand, Atax, Btep, Bspo, Iacu, Ipal, Ipar, Ipat, Isph, Istr, Ipli, ...
## 
## ‚Ñπ Use `spec()` to retrieve the full column specification for this data.
## ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.
```

```r
problems(dinocyst)
```
]

If **readr** encounters problems reading a file it will attempt to do it's best to read it in

It will print a warning &amp;mdash; don't ignore it! Use `problems()` to see what the problems were

---

# Writing rectangular data

There are a few functions to remember for writing data

* writing comma delimited files &amp;mdash; `write_csv(x, "file.csv")`

* writing semi-colon delimited files &amp;mdash; `write_csv2(x, "file2.csv")`

* writing files with any delimiter &amp;mdash; `write_delim(x, "file.txt", delim = "|")`

* writing tab delimited files &amp;mdash; `write_tsv(x, "file.tsv")`

* writing CSV for excel &amp;mdash; `write_excel_csv(x, "file.csv")`

---

# Writing rectangular data

The first argument is the object to write to disk

The second argument is the path, which includes the *filename*

* `path = 'file.csv'` saves `file.csv` in the current working directory
* `path = 'output_data/file.csv'` saves `file.csv` in folder `output_data` of the working directory
* `path = '../output_data/file.csv'` saves `file.csv` in folder `output_data` *one level up* from working directory
* `path = here('output_data', 'file.csv')` saves `file.csv` in `output_data` folder in the project root

---

# Reading a writing R objects to disk

**readr** provides functions to serialize R objects to disk

* `read_rds('obj.rds)` reads a serialized object from disk

* `write_rds(obj, 'obj.rds')` serializes `obj` to disk

---
class: inverse middle center subsection

# Reading Excel sheets

---

# Reading Excel sheets

The **readxl** package provides a small set of functions for *reading from* Excel sheets and workbooks

Three main functions

1. `read_xls()` reads from older Office/Excel formatted files
2. `read_xlsx()` reads from newer Office/Excel formatted files
3. `read_excel()` determines which type of file you have, then call one or the other of `read_xls()` or `read_xlsx()` as needed

---

# Reading Excel sheets

To list all the sheets in a file use `excel_sheets()`


```r
xl_file &lt;- here("data", "dinocyst.xlsx")
excel_sheets(xl_file)
```

```
## [1] "Table S 2" "duplicate"
```

---

# Reading Excel sheets

Say we wanted to read sheet 2, we could


```r
dinocyst &lt;- read_excel(xl_file, sheet = 2, range = "A3:BT1971")
```

or by name


```r
dinocyst &lt;- read_excel(xl_file, sheet = "duplicate", range = "A3:BT1971")
dinocyst
```

```
## # A tibble: 1,968 √ó 72
##    Site numb‚Ä¶¬π  Aand  Atax  Btep  Bspo  Iacu  Ipal  Ipar  Ipat  Isph  Istr  Ipli
##    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 E003            0 0      0        0     0     0     0     0     0     0     0
##  2 E004            0 0      1.09     0     0     0     0     0     0     0     0
##  3 E005            0 0      0        0     0     0     0     0     0     0     0
##  4 E006            0 0.714  0        0     0     0     0     0     0     0     0
##  5 E007            0 0.488  0        0     0     0     0     0     0     0     0
##  6 E008            0 0      0        0     0     0     0     0     0     0     0
##  7 E010            0 0      0        0     0     0     0     0     0     0     0
##  8 E012            0 0      0        0     0     0     0     0     0     0     0
##  9 E013            0 0      0        0     0     0     0     0     0     0     0
## 10 E014            0 0      0        0     0     0     0     0     0     0     0
## # ‚Ä¶ with 1,958 more rows, 60 more variables: Ivel &lt;dbl&gt;, Ijap &lt;dbl&gt;,
## #   Lmac &lt;dbl&gt;, Mcho &lt;dbl&gt;, Nlab &lt;dbl&gt;, Nrig &lt;dbl&gt;, Ocen &lt;dbl&gt;, Oisr &lt;dbl&gt;,
## #   Ojan &lt;dbl&gt;, Olon &lt;dbl&gt;, Ogig &lt;dbl&gt;, Pzoh &lt;dbl&gt;, Pret &lt;dbl&gt;, Smem &lt;dbl&gt;,
## #   Sdel &lt;dbl&gt;, Selo &lt;dbl&gt;, Sram &lt;dbl&gt;, Sbel &lt;dbl&gt;, Sben &lt;dbl&gt;, Sbul &lt;dbl&gt;,
## #   Slaz &lt;dbl&gt;, Smir &lt;dbl&gt;, Sgra &lt;dbl&gt;, Spac &lt;dbl&gt;, Sspp &lt;dbl&gt;, Tpel &lt;dbl&gt;,
## #   Pdal &lt;dbl&gt;, Stri &lt;dbl&gt;, Imin &lt;dbl&gt;, Imic &lt;dbl&gt;, Ibre &lt;dbl&gt;, Ekar &lt;dbl&gt;,
## #   Bspp &lt;dbl&gt;, Dubr &lt;dbl&gt;, Peri &lt;dbl&gt;, Lspp &lt;dbl&gt;, Snep &lt;dbl&gt;, Xxan &lt;dbl&gt;, ‚Ä¶
```

---

# Reading Excel sheets

Can use `col_types` argument to tell **readxl** what data types to expect

The default is `NULL` which guess from `guess_max` rows of the data

Other option is to pass it a vector of one or more of these options

* `"skip"`,
* `"guess"`,
* `"logical"`,
* `"numeric"`,
* `"date"`,
* `"text"`, or
* `"list"`

Note this is the complete list &amp;mdash; shorter than types for **readr** and no abbreviations

---

# Reading Excel sheets


```r
col_types &lt;- rep(c('text', 'numeric'), times = c(1, 71))
(dino_xl &lt;- read_excel(xl_file, range = "A3:BT1971", col_types = col_types))
```

```
## # A tibble: 1,968 √ó 72
##    Site numb‚Ä¶¬π  Aand  Atax  Btep  Bspo  Iacu  Ipal  Ipar  Ipat  Isph  Istr  Ipli
##    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 E003            0 0      0        0     0     0     0     0     0     0     0
##  2 E004            0 0      1.09     0     0     0     0     0     0     0     0
##  3 E005            0 0      0        0     0     0     0     0     0     0     0
##  4 E006            0 0.714  0        0     0     0     0     0     0     0     0
##  5 E007            0 0.488  0        0     0     0     0     0     0     0     0
##  6 E008            0 0      0        0     0     0     0     0     0     0     0
##  7 E010            0 0      0        0     0     0     0     0     0     0     0
##  8 E012            0 0      0        0     0     0     0     0     0     0     0
##  9 E013            0 0      0        0     0     0     0     0     0     0     0
## 10 E014            0 0      0        0     0     0     0     0     0     0     0
## # ‚Ä¶ with 1,958 more rows, 60 more variables: Ivel &lt;dbl&gt;, Ijap &lt;dbl&gt;,
## #   Lmac &lt;dbl&gt;, Mcho &lt;dbl&gt;, Nlab &lt;dbl&gt;, Nrig &lt;dbl&gt;, Ocen &lt;dbl&gt;, Oisr &lt;dbl&gt;,
## #   Ojan &lt;dbl&gt;, Olon &lt;dbl&gt;, Ogig &lt;dbl&gt;, Pzoh &lt;dbl&gt;, Pret &lt;dbl&gt;, Smem &lt;dbl&gt;,
## #   Sdel &lt;dbl&gt;, Selo &lt;dbl&gt;, Sram &lt;dbl&gt;, Sbel &lt;dbl&gt;, Sben &lt;dbl&gt;, Sbul &lt;dbl&gt;,
## #   Slaz &lt;dbl&gt;, Smir &lt;dbl&gt;, Sgra &lt;dbl&gt;, Spac &lt;dbl&gt;, Sspp &lt;dbl&gt;, Tpel &lt;dbl&gt;,
## #   Pdal &lt;dbl&gt;, Stri &lt;dbl&gt;, Imin &lt;dbl&gt;, Imic &lt;dbl&gt;, Ibre &lt;dbl&gt;, Ekar &lt;dbl&gt;,
## #   Bspp &lt;dbl&gt;, Dubr &lt;dbl&gt;, Peri &lt;dbl&gt;, Lspp &lt;dbl&gt;, Snep &lt;dbl&gt;, Xxan &lt;dbl&gt;, ‚Ä¶
```

---
class: inverse middle center subsection

# Working directory

---

# Working directory

Throughout we've been specifying paths to files, either explicitly or via the **here** üì¶

It is important to know where working directory is

In rstudio.cloud, R starts in the `project` folder

Use `getwd()` to query the working directory


```r
getwd()
```

```
## [1] "/home/au690221/work/teaching/acme/2022/repo/01-monday"
```

---

# Paths

Refer to files with relative paths if you want to share your work / scripts easily

But you still need to consider relative to what

Makes sense to always work from the same root directory for a given project

You should always start R in that root directory (use RStudio projects)

Refer to files as relative to the project root

---

# `here`

.row[

.col-6[

Helps you build relative paths

Heuristics help find the base of the project

* a `.here` file
* a file matching `[.]Rproj$`
* a `.git` file
* ...

]

.col-6[
&lt;img src="resources/here.png" width="100%" /&gt;
]

]


```r
here("data", "dinocyst-spp.csv")
```

```
## [1] "/home/au690221/work/teaching/acme/2022/repo/data/dinocyst-spp.csv"
```

---

# Pangaea

Pangaea is a well-curated data repository for the palaeo sciences

The *pangaear* üì¶ is an R interface to the Pangaear API

Lot of functionality, but a major function is `pg_data()` to download data sets from a Pangaea DOI

---

# Pangaea

Data from Stein *et al* JQS [10.1002/jqs.2929](https://doi.org/10.1002/jqs.2929)


```r
library("pangaear")
doi &lt;- "10.1594/PANGAEA.868790"
ara2b &lt;- pg_data(doi)
```

---

# Pangaea &amp;mdash; look at object


```r
ara2b
```

```
## [[1]]
## &lt;Pangaea data&gt; 10.1594/PANGAEA.868790
##   parent doi: 10.1594/PANGAEA.868790
##   url:        https://doi.org/10.1594/PANGAEA.868790
##   citation:   Stein, Ruediger; Fahl, Kirsten; Schade, Inka; Manerung, Adelina; Wassmuth, Saskia; Niessen, Frank; Nam, Seung-Il (2017): (Table 2) Biomarker proxies on sediment core ARA2B-1A. PANGAEA, https://doi.org/10.1594/PANGAEA.868790, In supplement to: Stein, R et al. (2017): Holocene variability in sea ice cover, primary production, and Pacific-Water inflow and climate change in the Chukchi and East Siberian Seas (Arctic Ocean). Journal of Quaternary Science, https://doi.org/10.1002/jqs.2929
##   path:       /home/au690221/.cache/R/pangaear/10_1594_PANGAEA_868790.txt
##   data:
## # A tibble: 110 √ó 15
##    `Depth [m]` Age [ka‚Ä¶¬π TOC [‚Ä¶¬≤ Brass‚Ä¶¬≥ Brass‚Ä¶‚Å¥ Dinos‚Ä¶‚Åµ Dinos‚Ä¶‚Å∂ Campe‚Ä¶‚Å∑ Campe‚Ä¶‚Å∏
##          &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1        0        0        1.57   0.904    57.5   0.284   18.0    1.26     80.0
##  2        0.05     0.164    1.44   0.711    49.4   0.402   27.9    0.865    60.1
##  3        0.1      0.329    1.45   0.369    25.4   0.188   13.0    0.338    23.3
##  4        0.15     0.493    1.33   0.359    27.0   0.179   13.5    0.341    25.7
##  5        0.2      0.658    1.25   0.404    32.2   0.178   14.2    0.378    30.2
##  6        0.25     0.822    1.24   0.632    50.9   0.338   27.2    0.543    43.7
##  7        0.3      0.987    1.24   0.596    48.0   0.274   22.0    0.606    48.7
##  8        0.35     1.15     1.21   0.515    42.6   0.277   22.9    0.5      41.4
##  9        0.4      1.32     1.41   0.361    25.6   0.13     9.27   0.259    18.4
## 10        0.45     1.48     1.24   0.298    24.0   0.103    8.31   0.244    19.7
## # ‚Ä¶ with 100 more rows, 6 more variables: `Œ≤-Sitosterol/sed [¬µg/g]` &lt;dbl&gt;,
## #   `Œ≤-Sitosterol/TOC [¬µg/g]` &lt;dbl&gt;, `IP25/sed [¬µg/g]` &lt;dbl&gt;,
## #   `IP25/TOC [¬µg/g]` &lt;dbl&gt;, PBIP25 &lt;dbl&gt;, PDIP25 &lt;dbl&gt;, and abbreviated
## #   variable names ¬π‚Äã`Age [ka BP]`, ¬≤‚Äã`TOC [%]`, ¬≥‚Äã`Brassicasterol/sed [¬µg/g]`,
## #   ‚Å¥‚Äã`Brassicasterol/TOC [¬µg/g]`, ‚Åµ‚Äã`Dinosterol/sed [¬µg/g]`,
## #   ‚Å∂‚Äã`Dinosterol/TOC [¬µg/g]`, ‚Å∑‚Äã`Campesterol/sed [¬µg/g]`,
## #   ‚Å∏‚Äã`Campesterol/TOC [¬µg/g]`
```

---

# Pangaea &amp;mdash; extract data


```r
ara2b_df &lt;- ara2b[[1]]$data
ara2b_df
```

```
## # A tibble: 110 √ó 15
##    `Depth [m]` Age [ka‚Ä¶¬π TOC [‚Ä¶¬≤ Brass‚Ä¶¬≥ Brass‚Ä¶‚Å¥ Dinos‚Ä¶‚Åµ Dinos‚Ä¶‚Å∂ Campe‚Ä¶‚Å∑ Campe‚Ä¶‚Å∏
##          &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1        0        0        1.57   0.904    57.5   0.284   18.0    1.26     80.0
##  2        0.05     0.164    1.44   0.711    49.4   0.402   27.9    0.865    60.1
##  3        0.1      0.329    1.45   0.369    25.4   0.188   13.0    0.338    23.3
##  4        0.15     0.493    1.33   0.359    27.0   0.179   13.5    0.341    25.7
##  5        0.2      0.658    1.25   0.404    32.2   0.178   14.2    0.378    30.2
##  6        0.25     0.822    1.24   0.632    50.9   0.338   27.2    0.543    43.7
##  7        0.3      0.987    1.24   0.596    48.0   0.274   22.0    0.606    48.7
##  8        0.35     1.15     1.21   0.515    42.6   0.277   22.9    0.5      41.4
##  9        0.4      1.32     1.41   0.361    25.6   0.13     9.27   0.259    18.4
## 10        0.45     1.48     1.24   0.298    24.0   0.103    8.31   0.244    19.7
## # ‚Ä¶ with 100 more rows, 6 more variables: `Œ≤-Sitosterol/sed [¬µg/g]` &lt;dbl&gt;,
## #   `Œ≤-Sitosterol/TOC [¬µg/g]` &lt;dbl&gt;, `IP25/sed [¬µg/g]` &lt;dbl&gt;,
## #   `IP25/TOC [¬µg/g]` &lt;dbl&gt;, PBIP25 &lt;dbl&gt;, PDIP25 &lt;dbl&gt;, and abbreviated
## #   variable names ¬π‚Äã`Age [ka BP]`, ¬≤‚Äã`TOC [%]`, ¬≥‚Äã`Brassicasterol/sed [¬µg/g]`,
## #   ‚Å¥‚Äã`Brassicasterol/TOC [¬µg/g]`, ‚Åµ‚Äã`Dinosterol/sed [¬µg/g]`,
## #   ‚Å∂‚Äã`Dinosterol/TOC [¬µg/g]`, ‚Å∑‚Äã`Campesterol/sed [¬µg/g]`,
## #   ‚Å∏‚Äã`Campesterol/TOC [¬µg/g]`
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
